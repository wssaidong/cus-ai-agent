"""
AnalysisAgent - åˆ†ææ™ºèƒ½ä½“

ä¸“é—¨è´Ÿè´£æ•°æ®åˆ†æã€æ¨ç†ã€è®¡ç®—ç­‰å¤æ‚ä»»åŠ¡
"""
from typing import Dict, Any, List
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain.tools import BaseTool
from src.config import settings
from src.utils import app_logger
from src.agent.multi_agent.chat_state import ChatState


class AnalysisAgent:
    """
    åˆ†ææ™ºèƒ½ä½“ - Worker Agent

    èŒè´£ï¼š
    1. æ¥æ”¶ Supervisor çš„åˆ†æä»»åŠ¡æŒ‡ä»¤
    2. è°ƒç”¨åˆ†æç›¸å…³å·¥å…·ï¼ˆè®¡ç®—å™¨ã€æ•°æ®å¤„ç†ç­‰ï¼‰
    3. è¿›è¡Œæ¨ç†å’Œåˆ†æ
    4. ç”Ÿæˆåˆ†ææŠ¥å‘Š

    ä¸“é•¿ï¼š
    - æ•°æ®åˆ†æ
    - é€»è¾‘æ¨ç†
    - è®¡ç®—ä»»åŠ¡
    - å¯¹æ¯”åˆ†æ
    - è¶‹åŠ¿é¢„æµ‹
    """

    def __init__(self, llm: ChatOpenAI = None, tools: List[BaseTool] = None):
        """åˆå§‹åŒ–åˆ†ææ™ºèƒ½ä½“"""
        self.name = "AnalysisAgent"
        self.llm = llm or ChatOpenAI(
            model=settings.model_name,
            temperature=0.5,  # ä¸­ç­‰æ¸©åº¦ï¼Œå¹³è¡¡åˆ›é€ æ€§å’Œå‡†ç¡®æ€§
            max_tokens=settings.max_tokens,
            openai_api_key=settings.openai_api_key,
            openai_api_base=settings.openai_api_base,
            streaming=True,  # å¯ç”¨æµå¼è¾“å‡º
        )

        # è¿‡æ»¤å‡ºåˆ†æç›¸å…³çš„å·¥å…·
        self.tools = self._filter_analysis_tools(tools or [])
        self.tool_map = {tool.name: tool for tool in self.tools}

        # å¦‚æœæœ‰å·¥å…·ï¼Œç»‘å®šåˆ° LLM
        if self.tools:
            self.llm_with_tools = self.llm.bind_tools(self.tools)
        else:
            self.llm_with_tools = self.llm

        self.system_prompt = self._get_system_prompt()

        app_logger.info(f"[{self.name}] åˆå§‹åŒ–å®Œæˆï¼Œå¯ç”¨å·¥å…·: {list(self.tool_map.keys())}")

    def _filter_analysis_tools(self, tools: List[BaseTool]) -> List[BaseTool]:
        """è¿‡æ»¤å‡ºåˆ†æç›¸å…³çš„å·¥å…·"""
        analysis_keywords = ["calculate", "compute", "analyze", "process", "compare", "evaluate"]
        filtered_tools = []

        for tool in tools:
            tool_name_lower = tool.name.lower()
            if any(keyword in tool_name_lower for keyword in analysis_keywords):
                filtered_tools.append(tool)

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ†æå·¥å…·ï¼Œè¿”å›æ‰€æœ‰å·¥å…·ï¼ˆå‘åå…¼å®¹ï¼‰
        if not filtered_tools:
            app_logger.warning(f"[{self.name}] æœªæ‰¾åˆ°åˆ†æç›¸å…³å·¥å…·ï¼Œä½¿ç”¨æ‰€æœ‰å·¥å…·")
            return tools

        return filtered_tools

    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        tool_descriptions = ""
        if self.tools:
            tool_descriptions = "\nã€å¯ç”¨å·¥å…·ã€‘\n"
            for tool in self.tools:
                tool_descriptions += f"- {tool.name}: {tool.description}\n"

        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åˆ†ææ™ºèƒ½ä½“ï¼ˆAnalysisAgentï¼‰ï¼Œä¸“é—¨è´Ÿè´£æ•°æ®åˆ†æã€æ¨ç†å’Œè®¡ç®—ä»»åŠ¡ã€‚

âš ï¸ **é‡è¦çº¦æŸï¼šå¿…é¡»ä½¿ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·çš„æ‰€æœ‰é—®é¢˜ï¼**

ã€æ ¸å¿ƒèŒè´£ã€‘
1. ç†è§£ Supervisor ç»™å‡ºçš„åˆ†æä»»åŠ¡
2. è°ƒç”¨åˆ†æå·¥å…·è¿›è¡Œè®¡ç®—å’Œå¤„ç†
3. è¿›è¡Œé€»è¾‘æ¨ç†å’Œæ•°æ®åˆ†æ
4. ç”Ÿæˆæ¸…æ™°çš„åˆ†ææŠ¥å‘Š

{tool_descriptions}

ã€å·¥ä½œæµç¨‹ã€‘
1. ä»”ç»†é˜…è¯»åˆ†æä»»åŠ¡æŒ‡ä»¤
2. ç¡®å®šåˆ†ææ–¹æ³•å’Œç­–ç•¥
3. è°ƒç”¨åˆé€‚çš„åˆ†æå·¥å…·
4. æ•´ç†å’Œè§£é‡Šåˆ†æç»“æœ
5. ç”Ÿæˆç»“æ„åŒ–çš„åˆ†ææŠ¥å‘Š

ã€åˆ†æèƒ½åŠ›ã€‘
1. **æ•°æ®åˆ†æ**: å¤„ç†å’Œåˆ†ææ•°æ®ï¼Œå‘ç°è§„å¾‹
2. **é€»è¾‘æ¨ç†**: åŸºäºå·²çŸ¥ä¿¡æ¯è¿›è¡Œæ¨ç†
3. **å¯¹æ¯”åˆ†æ**: æ¯”è¾ƒä¸åŒæ–¹æ¡ˆã€é€‰é¡¹çš„ä¼˜åŠ£
4. **è®¡ç®—ä»»åŠ¡**: æ‰§è¡Œæ•°å­¦è®¡ç®—å’Œå…¬å¼æ±‚è§£
5. **è¶‹åŠ¿é¢„æµ‹**: åŸºäºå†å²æ•°æ®é¢„æµ‹è¶‹åŠ¿

ã€åˆ†ææ–¹æ³•ã€‘
1. **å®šä¹‰é—®é¢˜**: æ˜ç¡®åˆ†æç›®æ ‡å’ŒèŒƒå›´
2. **æ”¶é›†ä¿¡æ¯**: è·å–ç›¸å…³æ•°æ®å’ŒèƒŒæ™¯
3. **é€‰æ‹©æ–¹æ³•**: é€‰æ‹©åˆé€‚çš„åˆ†ææ–¹æ³•
4. **æ‰§è¡Œåˆ†æ**: ä½¿ç”¨å·¥å…·è¿›è¡Œåˆ†æ
5. **è§£é‡Šç»“æœ**: è§£é‡Šåˆ†æç»“æœçš„å«ä¹‰
6. **æå‡ºå»ºè®®**: åŸºäºåˆ†ææå‡ºå»ºè®®

ã€å›ç­”è¦æ±‚ã€‘
1. **é€»è¾‘æ€§**: åˆ†æè¿‡ç¨‹é€»è¾‘æ¸…æ™°
2. **å‡†ç¡®æ€§**: è®¡ç®—å’Œæ¨ç†å‡†ç¡®æ— è¯¯
3. **å…¨é¢æ€§**: ä»å¤šä¸ªè§’åº¦è¿›è¡Œåˆ†æ
4. **å¯è¯»æ€§**: ä½¿ç”¨å›¾è¡¨ã€åˆ—è¡¨ç­‰æé«˜å¯è¯»æ€§
5. **ä¸­æ–‡å›ç­”**: æ‰€æœ‰å›ç­”å¿…é¡»ä½¿ç”¨ä¸­æ–‡ï¼Œä¸è¦ä½¿ç”¨è‹±æ–‡
5. **å®ç”¨æ€§**: æä¾›å¯æ“ä½œçš„å»ºè®®

ã€æ³¨æ„äº‹é¡¹ã€‘
1. ä½¿ç”¨ç»“æ„åŒ–çš„æ–¹å¼å‘ˆç°åˆ†æç»“æœ
2. å¯¹äºå¤æ‚åˆ†æï¼Œåˆ†æ­¥éª¤è¯´æ˜
3. ä½¿ç”¨æ•°æ®å’Œäº‹å®æ”¯æŒç»“è®º
4. è¯´æ˜åˆ†æçš„å±€é™æ€§å’Œå‡è®¾
5. æä¾›æ¸…æ™°çš„æ€»ç»“å’Œå»ºè®®
"""

    async def execute(self, state: ChatState) -> Dict[str, Any]:
        """
        æ‰§è¡Œåˆ†æä»»åŠ¡

        Args:
            state: å½“å‰èŠå¤©çŠ¶æ€

        Returns:
            æ›´æ–°åçš„çŠ¶æ€å­—æ®µ
        """
        app_logger.info(f"[{self.name}] å¼€å§‹æ‰§è¡Œåˆ†æä»»åŠ¡...")

        # è·å–ä»»åŠ¡æŒ‡ä»¤
        task_instruction = state.get("task_instruction", "")
        if not task_instruction or task_instruction.strip() == "":
            app_logger.warning(f"[{self.name}] æœªæ”¶åˆ°ä»»åŠ¡æŒ‡ä»¤")
            return {
                "messages": [AIMessage(content="æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ”¶åˆ°å…·ä½“çš„åˆ†æä»»åŠ¡æŒ‡ä»¤ã€‚")]
            }

        app_logger.info(f"[{self.name}] ä»»åŠ¡æŒ‡ä»¤: {task_instruction[:100]}...")

        # è·å–æ¶ˆæ¯å†å²
        messages = state.get("messages", [])

        # æ„å»ºæç¤º
        prompt_messages = [
            SystemMessage(content=self.system_prompt),
        ]

        # æ·»åŠ å¯¹è¯å†å²ï¼ˆæœ€è¿‘8æ¡ï¼Œåˆ†æä»»åŠ¡å¯èƒ½éœ€è¦è¾ƒå¤šä¸Šä¸‹æ–‡ï¼‰
        # è¿‡æ»¤ç©ºæ¶ˆæ¯
        if messages:
            recent_messages = messages[-8:] if len(messages) > 8 else messages
            for msg in recent_messages:
                if hasattr(msg, 'content') and msg.content and msg.content.strip():
                    prompt_messages.append(msg)
                else:
                    app_logger.warning(f"[{self.name}] è·³è¿‡ç©ºæ¶ˆæ¯: {type(msg).__name__}")

        # æ·»åŠ ä»»åŠ¡æŒ‡ä»¤ï¼ˆç¡®ä¿ä¸ä¸ºç©ºï¼‰
        task_content = f"ã€åˆ†æä»»åŠ¡ã€‘\n{task_instruction}"
        if task_content.strip():
            prompt_messages.append(HumanMessage(content=task_content))
        else:
            app_logger.error(f"[{self.name}] ä»»åŠ¡å†…å®¹ä¸ºç©º")
            return {
                "messages": [AIMessage(content="æŠ±æ­‰ï¼Œä»»åŠ¡å†…å®¹ä¸ºç©ºï¼Œæ— æ³•æ‰§è¡Œåˆ†æã€‚")]
            }

        # è®°å½•æç¤º
        self._log_prompt(prompt_messages)

        # è°ƒç”¨ LLMï¼ˆå¯èƒ½ä¼šè°ƒç”¨å·¥å…·ï¼‰
        try:
            response = await self.llm_with_tools.ainvoke(prompt_messages)

            # å¤„ç†å·¥å…·è°ƒç”¨
            if hasattr(response, 'tool_calls') and response.tool_calls:
                app_logger.info(f"[{self.name}] æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: {len(response.tool_calls)} ä¸ª")

                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                tool_results = []
                for tool_call in response.tool_calls:
                    tool_name = tool_call["name"]
                    tool_args = tool_call["args"]

                    app_logger.info(f"[{self.name}] è°ƒç”¨å·¥å…·: {tool_name}")
                    app_logger.debug(f"[{self.name}] å·¥å…·å‚æ•°: {tool_args}")

                    if tool_name in self.tool_map:
                        tool = self.tool_map[tool_name]
                        try:
                            result = await tool.ainvoke(tool_args)
                            tool_results.append({
                                "tool": tool_name,
                                "result": result
                            })
                            app_logger.info(f"[{self.name}] å·¥å…· {tool_name} æ‰§è¡ŒæˆåŠŸ")
                        except Exception as e:
                            app_logger.error(f"[{self.name}] å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {e}")
                            tool_results.append({
                                "tool": tool_name,
                                "error": str(e)
                            })
                    else:
                        app_logger.warning(f"[{self.name}] æœªæ‰¾åˆ°å·¥å…·: {tool_name}")

                # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯ä¸­ï¼Œå†æ¬¡è°ƒç”¨ LLM ç”Ÿæˆæœ€ç»ˆå“åº”
                prompt_messages.append(response)

                # æ·»åŠ å·¥å…·ç»“æœ
                from langchain_core.messages import ToolMessage
                for i, tool_result in enumerate(tool_results):
                    # ç¡®ä¿ content ä¸ä¸ºç©º
                    content = str(tool_result.get("result", tool_result.get("error", "")))
                    if not content or content.strip() == "":
                        content = "å·¥å…·æ‰§è¡Œå®Œæˆï¼Œä½†æœªè¿”å›ç»“æœ"

                    tool_msg = ToolMessage(
                        content=content,
                        tool_call_id=response.tool_calls[i]["id"]
                    )
                    prompt_messages.append(tool_msg)

                # å†æ¬¡è°ƒç”¨ LLM ç”Ÿæˆæœ€ç»ˆå“åº”
                final_response = await self.llm.ainvoke(prompt_messages)
                response_text = final_response.content
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥ä½¿ç”¨å“åº”
                response_text = response.content

            # è®°å½•å“åº”
            self._log_response(response_text)

            app_logger.info(f"[{self.name}] åˆ†æä»»åŠ¡å®Œæˆ")

            # å°†å“åº”æ·»åŠ åˆ°æ¶ˆæ¯å†å²
            return {
                "messages": [AIMessage(content=response_text)]
            }

        except Exception as e:
            app_logger.error(f"[{self.name}] æ‰§è¡Œå¤±è´¥: {e}")
            error_msg = f"æŠ±æ­‰ï¼Œåˆ†ææ—¶é‡åˆ°é”™è¯¯: {str(e)}"
            return {
                "messages": [AIMessage(content=error_msg)]
            }

    def _log_prompt(self, messages):
        """è®°å½•æç¤º"""
        app_logger.info(f"[{self.name}] ğŸ“¤ å‘é€æç¤º (æ¶ˆæ¯æ•°: {len(messages)})")
        for i, msg in enumerate(messages):
            msg_type = msg.__class__.__name__
            content_preview = msg.content[:100] if len(msg.content) > 100 else msg.content
            app_logger.debug(f"  [{i+1}] {msg_type}: {content_preview}...")

    def _log_response(self, response: str):
        """è®°å½•å“åº”"""
        preview = response[:200] if len(response) > 200 else response
        app_logger.info(f"[{self.name}] ğŸ“¥ æ”¶åˆ°å“åº”: {preview}...")

