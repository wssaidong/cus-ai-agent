"""
SearchAgent - æœç´¢æ™ºèƒ½ä½“

ä¸“é—¨è´Ÿè´£çŸ¥è¯†åº“æœç´¢å’Œä¿¡æ¯æ£€ç´¢ä»»åŠ¡
"""
from typing import Dict, Any, List
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain.tools import BaseTool
from src.config import settings
from src.utils import app_logger
from src.agent.multi_agent.chat_state import ChatState


class SearchAgent:
    """
    æœç´¢æ™ºèƒ½ä½“ - Worker Agent
    
    èŒè´£ï¼š
    1. æ¥æ”¶ Supervisor çš„æœç´¢ä»»åŠ¡æŒ‡ä»¤
    2. è°ƒç”¨æœç´¢ç›¸å…³å·¥å…·ï¼ˆRAGã€çŸ¥è¯†åº“æŸ¥è¯¢ç­‰ï¼‰
    3. æ•´ç†å’Œå‘ˆç°æœç´¢ç»“æœ
    
    ä¸“é•¿ï¼š
    - çŸ¥è¯†åº“æœç´¢
    - ä¿¡æ¯æ£€ç´¢
    - ç›¸å…³æ€§æ’åº
    - ç»“æœæ‘˜è¦
    """
    
    def __init__(self, llm: ChatOpenAI = None, tools: List[BaseTool] = None):
        """åˆå§‹åŒ–æœç´¢æ™ºèƒ½ä½“"""
        self.name = "SearchAgent"
        self.llm = llm or ChatOpenAI(
            model=settings.model_name,
            temperature=0.3,  # è¾ƒä½æ¸©åº¦ï¼Œä¿æŒæœç´¢ç»“æœçš„å‡†ç¡®æ€§
            max_tokens=settings.max_tokens,
            openai_api_key=settings.openai_api_key,
            openai_api_base=settings.openai_api_base,
        )
        
        # è¿‡æ»¤å‡ºæœç´¢ç›¸å…³çš„å·¥å…·
        self.tools = self._filter_search_tools(tools or [])
        self.tool_map = {tool.name: tool for tool in self.tools}
        
        # å¦‚æœæœ‰å·¥å…·ï¼Œç»‘å®šåˆ° LLM
        if self.tools:
            self.llm_with_tools = self.llm.bind_tools(self.tools)
        else:
            self.llm_with_tools = self.llm
        
        self.system_prompt = self._get_system_prompt()
        
        app_logger.info(f"[{self.name}] åˆå§‹åŒ–å®Œæˆï¼Œå¯ç”¨å·¥å…·: {list(self.tool_map.keys())}")
    
    def _filter_search_tools(self, tools: List[BaseTool]) -> List[BaseTool]:
        """è¿‡æ»¤å‡ºæœç´¢ç›¸å…³çš„å·¥å…·"""
        search_keywords = ["search", "query", "retrieve", "find", "lookup", "rag"]
        filtered_tools = []
        
        for tool in tools:
            tool_name_lower = tool.name.lower()
            if any(keyword in tool_name_lower for keyword in search_keywords):
                filtered_tools.append(tool)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœç´¢å·¥å…·ï¼Œè¿”å›æ‰€æœ‰å·¥å…·ï¼ˆå‘åå…¼å®¹ï¼‰
        if not filtered_tools:
            app_logger.warning(f"[{self.name}] æœªæ‰¾åˆ°æœç´¢ç›¸å…³å·¥å…·ï¼Œä½¿ç”¨æ‰€æœ‰å·¥å…·")
            return tools
        
        return filtered_tools
    
    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        tool_descriptions = ""
        if self.tools:
            tool_descriptions = "\nã€å¯ç”¨å·¥å…·ã€‘\n"
            for tool in self.tools:
                tool_descriptions += f"- {tool.name}: {tool.description}\n"
        
        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æœç´¢æ™ºèƒ½ä½“ï¼ˆSearchAgentï¼‰ï¼Œä¸“é—¨è´Ÿè´£çŸ¥è¯†åº“æœç´¢å’Œä¿¡æ¯æ£€ç´¢ã€‚

ã€æ ¸å¿ƒèŒè´£ã€‘
1. ç†è§£ Supervisor ç»™å‡ºçš„æœç´¢ä»»åŠ¡
2. è°ƒç”¨æœç´¢å·¥å…·æŸ¥è¯¢çŸ¥è¯†åº“
3. æ•´ç†å’Œå‘ˆç°æœç´¢ç»“æœ
4. æä¾›å‡†ç¡®ã€ç›¸å…³çš„ä¿¡æ¯

{tool_descriptions}

ã€å·¥ä½œæµç¨‹ã€‘
1. ä»”ç»†é˜…è¯»æœç´¢ä»»åŠ¡æŒ‡ä»¤
2. ç¡®å®šæœç´¢å…³é”®è¯å’ŒæŸ¥è¯¢ç­–ç•¥
3. è°ƒç”¨åˆé€‚çš„æœç´¢å·¥å…·
4. åˆ†ææœç´¢ç»“æœçš„ç›¸å…³æ€§
5. æ•´ç†æˆæ¸…æ™°ã€æ˜“æ‡‚çš„å›ç­”

ã€æœç´¢ç­–ç•¥ã€‘
1. **å…³é”®è¯æå–**: ä»ä»»åŠ¡ä¸­æå–æ ¸å¿ƒå…³é”®è¯
2. **å¤šè§’åº¦æœç´¢**: å°è¯•ä¸åŒçš„å…³é”®è¯ç»„åˆ
3. **ç›¸å…³æ€§åˆ¤æ–­**: è¯„ä¼°ç»“æœä¸é—®é¢˜çš„ç›¸å…³æ€§
4. **ç»“æœæ•´åˆ**: å°†å¤šä¸ªæ¥æºçš„ä¿¡æ¯æ•´åˆ
5. **æ¥æºæ ‡æ³¨**: è¯´æ˜ä¿¡æ¯æ¥æº

ã€å›ç­”è¦æ±‚ã€‘
1. **å‡†ç¡®æ€§**: ç¡®ä¿ä¿¡æ¯æ¥è‡ªçŸ¥è¯†åº“ï¼Œä¸ç¼–é€ 
2. **å®Œæ•´æ€§**: æä¾›å…¨é¢çš„æœç´¢ç»“æœ
3. **æ¸…æ™°æ€§**: ä½¿ç”¨æ¸…æ™°çš„ç»“æ„ç»„ç»‡ä¿¡æ¯
4. **ç›¸å…³æ€§**: åªè¿”å›ä¸é—®é¢˜ç›¸å…³çš„ä¿¡æ¯
5. **æ¥æºæ€§**: å¼•ç”¨çŸ¥è¯†åº“æ—¶è¯´æ˜æ¥æº

ã€æ³¨æ„äº‹é¡¹ã€‘
1. å¦‚æœæœç´¢ç»“æœä¸ºç©ºï¼Œè¯šå®å‘ŠçŸ¥ç”¨æˆ·
2. å¦‚æœç»“æœä¸å¤Ÿç›¸å…³ï¼Œè¯´æ˜æƒ…å†µå¹¶å»ºè®®è°ƒæ•´é—®é¢˜
3. å¼•ç”¨çŸ¥è¯†åº“ä¿¡æ¯æ—¶æ ‡æ³¨æ¥æº
4. ä½¿ç”¨åˆ—è¡¨ã€æ­¥éª¤ç­‰æ ¼å¼æé«˜å¯è¯»æ€§
5. å¦‚æœéœ€è¦å¤šæ¬¡æœç´¢ï¼Œè¯´æ˜æœç´¢ç­–ç•¥
"""
    
    async def execute(self, state: ChatState) -> Dict[str, Any]:
        """
        æ‰§è¡Œæœç´¢ä»»åŠ¡
        
        Args:
            state: å½“å‰èŠå¤©çŠ¶æ€
        
        Returns:
            æ›´æ–°åçš„çŠ¶æ€å­—æ®µ
        """
        app_logger.info(f"[{self.name}] å¼€å§‹æ‰§è¡Œæœç´¢ä»»åŠ¡...")
        
        # è·å–ä»»åŠ¡æŒ‡ä»¤
        task_instruction = state.get("task_instruction", "")
        if not task_instruction:
            app_logger.warning(f"[{self.name}] æœªæ”¶åˆ°ä»»åŠ¡æŒ‡ä»¤")
            return {}
        
        app_logger.info(f"[{self.name}] ä»»åŠ¡æŒ‡ä»¤: {task_instruction[:100]}...")
        
        # è·å–æ¶ˆæ¯å†å²
        messages = state["messages"]
        
        # æ„å»ºæç¤º
        prompt_messages = [
            SystemMessage(content=self.system_prompt),
        ]
        
        # æ·»åŠ å¯¹è¯å†å²ï¼ˆæœ€è¿‘5æ¡ï¼Œæœç´¢ä»»åŠ¡é€šå¸¸ä¸éœ€è¦å¤ªå¤šå†å²ï¼‰
        recent_messages = messages[-5:] if len(messages) > 5 else messages
        prompt_messages.extend(recent_messages)
        
        # æ·»åŠ ä»»åŠ¡æŒ‡ä»¤
        prompt_messages.append(
            HumanMessage(content=f"ã€æœç´¢ä»»åŠ¡ã€‘\n{task_instruction}")
        )
        
        # è®°å½•æç¤º
        self._log_prompt(prompt_messages)
        
        # è°ƒç”¨ LLMï¼ˆå¯èƒ½ä¼šè°ƒç”¨å·¥å…·ï¼‰
        try:
            response = await self.llm_with_tools.ainvoke(prompt_messages)
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            if hasattr(response, 'tool_calls') and response.tool_calls:
                app_logger.info(f"[{self.name}] æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: {len(response.tool_calls)} ä¸ª")
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                tool_results = []
                for tool_call in response.tool_calls:
                    tool_name = tool_call["name"]
                    tool_args = tool_call["args"]
                    
                    app_logger.info(f"[{self.name}] è°ƒç”¨å·¥å…·: {tool_name}")
                    app_logger.debug(f"[{self.name}] å·¥å…·å‚æ•°: {tool_args}")
                    
                    if tool_name in self.tool_map:
                        tool = self.tool_map[tool_name]
                        try:
                            result = await tool.ainvoke(tool_args)
                            tool_results.append({
                                "tool": tool_name,
                                "result": result
                            })
                            app_logger.info(f"[{self.name}] å·¥å…· {tool_name} æ‰§è¡ŒæˆåŠŸ")
                        except Exception as e:
                            app_logger.error(f"[{self.name}] å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {e}")
                            tool_results.append({
                                "tool": tool_name,
                                "error": str(e)
                            })
                    else:
                        app_logger.warning(f"[{self.name}] æœªæ‰¾åˆ°å·¥å…·: {tool_name}")
                
                # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯ä¸­ï¼Œå†æ¬¡è°ƒç”¨ LLM ç”Ÿæˆæœ€ç»ˆå“åº”
                prompt_messages.append(response)
                
                # æ·»åŠ å·¥å…·ç»“æœ
                from langchain_core.messages import ToolMessage
                for i, tool_result in enumerate(tool_results):
                    tool_msg = ToolMessage(
                        content=str(tool_result.get("result", tool_result.get("error", ""))),
                        tool_call_id=response.tool_calls[i]["id"]
                    )
                    prompt_messages.append(tool_msg)
                
                # å†æ¬¡è°ƒç”¨ LLM ç”Ÿæˆæœ€ç»ˆå“åº”
                final_response = await self.llm.ainvoke(prompt_messages)
                response_text = final_response.content
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥ä½¿ç”¨å“åº”
                response_text = response.content
            
            # è®°å½•å“åº”
            self._log_response(response_text)
            
            app_logger.info(f"[{self.name}] æœç´¢ä»»åŠ¡å®Œæˆ")
            
            # å°†å“åº”æ·»åŠ åˆ°æ¶ˆæ¯å†å²
            return {
                "messages": [AIMessage(content=response_text)]
            }
            
        except Exception as e:
            app_logger.error(f"[{self.name}] æ‰§è¡Œå¤±è´¥: {e}")
            error_msg = f"æŠ±æ­‰ï¼Œæœç´¢æ—¶é‡åˆ°é”™è¯¯: {str(e)}"
            return {
                "messages": [AIMessage(content=error_msg)]
            }
    
    def _log_prompt(self, messages):
        """è®°å½•æç¤º"""
        app_logger.info(f"[{self.name}] ğŸ“¤ å‘é€æç¤º (æ¶ˆæ¯æ•°: {len(messages)})")
        for i, msg in enumerate(messages):
            msg_type = msg.__class__.__name__
            content_preview = msg.content[:100] if len(msg.content) > 100 else msg.content
            app_logger.debug(f"  [{i+1}] {msg_type}: {content_preview}...")
    
    def _log_response(self, response: str):
        """è®°å½•å“åº”"""
        preview = response[:200] if len(response) > 200 else response
        app_logger.info(f"[{self.name}] ğŸ“¥ æ”¶åˆ°å“åº”: {preview}...")

