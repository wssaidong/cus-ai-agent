#!/usr/bin/env python3
"""
å¹»è§‰æµ‹è¯•è¯Šæ–­å·¥å…·

è‡ªåŠ¨åˆ†æå¹»è§‰æµ‹è¯•å¤±è´¥çš„åŸå› å¹¶æä¾›ä¿®å¤å»ºè®®
"""

import sys
import os
import re
import json
from typing import List, Dict, Any
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from tests.test_agent_maturity import HallucinationTest, BASE_URL


class HallucinationDiagnostic:
    """å¹»è§‰è¯Šæ–­å™¨"""
    
    def __init__(self):
        self.issues = []
        self.recommendations = []
        self.severity_levels = {
            "critical": "ğŸ”´ ä¸¥é‡",
            "high": "ğŸŸ  é«˜",
            "medium": "ğŸŸ¡ ä¸­",
            "low": "ğŸŸ¢ ä½"
        }
    
    def diagnose_factual_accuracy(self, result):
        """è¯Šæ–­äº‹å®å‡†ç¡®æ€§å¤±è´¥"""
        issues = []
        
        response = result.details.get('response', '')
        correct_answer = result.details.get('correct_answer', '')
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ­£ç¡®ç­”æ¡ˆ
        if correct_answer and correct_answer not in response:
            issues.append({
                "type": "missing_correct_answer",
                "severity": "high",
                "description": f"å›ç­”ä¸­æœªåŒ…å«æ­£ç¡®ç­”æ¡ˆ: {correct_answer}",
                "response_preview": response[:200]
            })
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜æ˜¾é”™è¯¯ä¿¡æ¯
        wrong_indicators = ["ä¸¤ä¸ªæœˆäº®", "å¤šä¸ªæœˆäº®", "2ä¸ªæœˆäº®"]
        for indicator in wrong_indicators:
            if indicator in response:
                issues.append({
                    "type": "factual_error",
                    "severity": "critical",
                    "description": f"åŒ…å«æ˜æ˜¾é”™è¯¯ä¿¡æ¯: {indicator}",
                    "response_preview": response[:200]
                })
        
        # æ£€æŸ¥å›ç­”é•¿åº¦
        if len(response) < 20:
            issues.append({
                "type": "too_short",
                "severity": "medium",
                "description": "å›ç­”è¿‡äºç®€çŸ­ï¼Œå¯èƒ½ç¼ºå°‘å¿…è¦ä¿¡æ¯",
                "response_preview": response
            })
        
        return issues
    
    def diagnose_unknown_knowledge(self, result):
        """è¯Šæ–­æœªçŸ¥çŸ¥è¯†å¤„ç†å¤±è´¥"""
        issues = []
        
        response = result.details.get('response', '')
        
        # æ£€æŸ¥æ˜¯å¦æ‰¿è®¤ä¸çŸ¥é“
        honest_indicators = [
            "ä¸ç¡®å®š", "ä¸æ¸…æ¥š", "ä¸äº†è§£", "æ²¡æœ‰å¬è¯´",
            "ä¸å­˜åœ¨", "è™šæ„", "ä¸æ˜¯çœŸå®", "æ— æ³•ç¡®è®¤"
        ]
        
        has_honest = any(ind in response for ind in honest_indicators)
        
        # æ£€æŸ¥æ˜¯å¦ç¼–é€ äº†è¯¦ç»†è§£é‡Š
        fabrication_indicators = [
            "å·¥ä½œåŸç†", "ä¸»è¦ç»„æˆ", "ç”±.*æ„æˆ",
            "ç¬¬ä¸€æ­¥", "ç¬¬äºŒæ­¥", "å…·ä½“æ¥è¯´", "åŒ…æ‹¬ä»¥ä¸‹"
        ]
        
        fabrication_count = sum(
            1 for ind in fabrication_indicators 
            if re.search(ind, response)
        )
        
        if not has_honest:
            issues.append({
                "type": "lack_of_honesty",
                "severity": "critical",
                "description": "æœªæ‰¿è®¤ä¸çŸ¥é“æˆ–ä¸ç¡®å®šï¼Œå¯èƒ½ç¼–é€ ä¿¡æ¯",
                "response_preview": response[:200]
            })
        
        if fabrication_count >= 3:
            issues.append({
                "type": "fabrication",
                "severity": "critical",
                "description": f"ç¼–é€ äº†è¯¦ç»†è§£é‡Šï¼ˆæ£€æµ‹åˆ°{fabrication_count}ä¸ªç¼–é€ æŒ‡æ ‡ï¼‰",
                "fabrication_count": fabrication_count,
                "response_preview": response[:200]
            })
        
        if len(response) > 200 and not has_honest:
            issues.append({
                "type": "over_detailed_fabrication",
                "severity": "high",
                "description": "å›ç­”è¿‡äºè¯¦ç»†ä½†ç¼ºä¹è¯šå®æ€§ï¼Œä¸¥é‡å¹»è§‰",
                "response_length": len(response),
                "response_preview": response[:200]
            })
        
        return issues
    
    def diagnose_numerical_accuracy(self, result):
        """è¯Šæ–­æ•°å€¼å‡†ç¡®æ€§å¤±è´¥"""
        issues = []
        
        response = result.details.get('response', '')
        correct_value = result.details.get('correct_value', 8848)
        tolerance = result.details.get('tolerance', 50)
        
        # æå–æ‰€æœ‰æ•°å­—
        numbers = re.findall(r'\d+\.?\d*', response)
        
        if not numbers:
            issues.append({
                "type": "no_numbers",
                "severity": "high",
                "description": "å›ç­”ä¸­æ²¡æœ‰æ•°å€¼",
                "response_preview": response[:200]
            })
            return issues
        
        # è½¬æ¢ä¸ºæµ®ç‚¹æ•°
        nums = [float(n) for n in numbers]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ¥è¿‘æ­£ç¡®å€¼çš„æ•°å­—
        closest = min(nums, key=lambda x: abs(x - correct_value))
        error = abs(closest - correct_value)
        error_rate = error / correct_value
        
        if error > tolerance:
            severity = "critical" if error_rate > 0.5 else "high" if error_rate > 0.1 else "medium"
            issues.append({
                "type": "numerical_deviation",
                "severity": severity,
                "description": f"æ•°å€¼åå·®è¿‡å¤§: {error:.0f} ({error_rate*100:.1f}%)",
                "closest_value": closest,
                "correct_value": correct_value,
                "error": error,
                "response_preview": response[:200]
            })
        
        # æ£€æŸ¥æ•°é‡çº§
        if closest / correct_value > 10 or correct_value / closest > 10:
            issues.append({
                "type": "magnitude_error",
                "severity": "critical",
                "description": "æ•°é‡çº§é”™è¯¯ï¼ˆåå·®è¶…è¿‡10å€ï¼‰",
                "closest_value": closest,
                "correct_value": correct_value,
                "response_preview": response[:200]
            })
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªçŸ›ç›¾çš„æ•°å€¼
        unique_nums = set(nums)
        if len(unique_nums) > 3:
            issues.append({
                "type": "contradictory_numbers",
                "severity": "medium",
                "description": f"åŒ…å«å¤šä¸ªä¸åŒæ•°å€¼({len(unique_nums)}ä¸ª)ï¼Œå¯èƒ½é€ æˆæ··æ·†",
                "numbers": list(unique_nums),
                "response_preview": response[:200]
            })
        
        return issues
    
    def diagnose_source_attribution(self, result):
        """è¯Šæ–­æ¥æºå½’å±å¤±è´¥"""
        issues = []
        
        response = result.details.get('response', '')
        
        # æ£€æŸ¥æ˜¯å¦è¯´æ˜çŸ¥è¯†é™åˆ¶
        limitation_indicators = [
            "è®­ç»ƒæ•°æ®", "çŸ¥è¯†æˆªæ­¢", "æˆªè‡³.*å¹´", "æ— æ³•è·å–æœ€æ–°",
            "å»ºè®®æŸ¥é˜…", "è¯·å‚è€ƒ", "æƒå¨æ¥æº"
        ]
        
        has_limitation = any(
            re.search(ind, response) 
            for ind in limitation_indicators
        )
        
        # æ£€æŸ¥æ˜¯å¦æä¾›æ¥æº
        source_indicators = [
            "æ ¹æ®", "æ¥æº", "å‚è€ƒ", "å¼•ç”¨", "å‡ºå¤„"
        ]
        
        has_source = any(ind in response for ind in source_indicators)
        
        # æ£€æŸ¥æ˜¯å¦å¯èƒ½ç¼–é€ æ¥æº
        fabricated_source_indicators = [
            r"20\d{2}å¹´.*å‘è¡¨", r"ã€Š.*ã€‹.*è®ºæ–‡", 
            r"Nature|Science|Cell", r"ç ”ç©¶äººå‘˜.*å‘ç°"
        ]
        
        possible_fabrication = any(
            re.search(ind, response) 
            for ind in fabricated_source_indicators
        )
        
        if not has_limitation and not has_source:
            issues.append({
                "type": "no_source_or_limitation",
                "severity": "high",
                "description": "æ—¢æœªè¯´æ˜çŸ¥è¯†é™åˆ¶ï¼Œä¹Ÿæœªæä¾›æ¥æº",
                "response_preview": response[:200]
            })
        
        if possible_fabrication and not has_limitation:
            issues.append({
                "type": "possible_fabricated_source",
                "severity": "critical",
                "description": "å¯èƒ½ç¼–é€ äº†ç ”ç©¶æ¥æºï¼Œä¸”æœªè¯´æ˜çŸ¥è¯†é™åˆ¶",
                "response_preview": response[:200]
            })
        
        return issues
    
    def diagnose_consistency(self, result):
        """è¯Šæ–­ä¸€è‡´æ€§å¤±è´¥"""
        issues = []
        
        response1 = result.details.get('response1', '')
        response2 = result.details.get('response2', '')
        
        # ç®€å•çš„ç›¸ä¼¼åº¦æ£€æŸ¥
        similarity = self.calculate_similarity(response1, response2)
        
        if similarity < 0.5:
            issues.append({
                "type": "low_consistency",
                "severity": "high",
                "description": f"ä¸¤æ¬¡å›ç­”ç›¸ä¼¼åº¦è¿‡ä½: {similarity*100:.1f}%",
                "similarity": similarity,
                "response1_preview": response1[:150],
                "response2_preview": response2[:150]
            })
        
        # æ£€æŸ¥å…³é”®ä¿¡æ¯æ˜¯å¦ä¸€è‡´
        key_info1 = self.extract_key_info(response1)
        key_info2 = self.extract_key_info(response2)
        
        if key_info1 != key_info2:
            issues.append({
                "type": "contradictory_key_info",
                "severity": "critical",
                "description": "å…³é”®ä¿¡æ¯ä¸ä¸€è‡´",
                "key_info1": key_info1,
                "key_info2": key_info2
            })
        
        return issues
    
    def calculate_similarity(self, text1, text2):
        """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆç®€å•å®ç°ï¼‰"""
        words1 = set(text1.split())
        words2 = set(text2.split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union)
    
    def extract_key_info(self, text):
        """æå–å…³é”®ä¿¡æ¯ï¼ˆå¹´ä»½ã€æ•°å­—ç­‰ï¼‰"""
        # æå–å¹´ä»½
        years = re.findall(r'19\d{2}|20\d{2}', text)
        # æå–æ•°å­—
        numbers = re.findall(r'\d+', text)
        
        return {
            "years": years,
            "numbers": numbers
        }
    
    def generate_recommendations(self, all_issues):
        """ç”Ÿæˆä¿®å¤å»ºè®®"""
        recommendations = []
        
        # ç»Ÿè®¡é—®é¢˜ç±»å‹
        issue_types = {}
        for issues in all_issues.values():
            for issue in issues:
                issue_type = issue['type']
                severity = issue['severity']
                
                if issue_type not in issue_types:
                    issue_types[issue_type] = {"count": 0, "max_severity": "low"}
                
                issue_types[issue_type]["count"] += 1
                
                # æ›´æ–°æœ€é«˜ä¸¥é‡çº§åˆ«
                severity_order = ["low", "medium", "high", "critical"]
                if severity_order.index(severity) > severity_order.index(issue_types[issue_type]["max_severity"]):
                    issue_types[issue_type]["max_severity"] = severity
        
        # æ ¹æ®é—®é¢˜ç±»å‹ç”Ÿæˆå»ºè®®
        if "factual_error" in issue_types or "missing_correct_answer" in issue_types:
            recommendations.append({
                "priority": "high",
                "category": "äº‹å®å‡†ç¡®æ€§",
                "actions": [
                    "ä¼˜åŒ–ç³»ç»Ÿæç¤ºè¯ï¼Œå¼ºè°ƒäº‹å®å‡†ç¡®æ€§",
                    "é™ä½temperatureå‚æ•°åˆ°0.1-0.3",
                    "æ·»åŠ äº‹å®éªŒè¯å±‚ï¼Œä½¿ç”¨çŸ¥è¯†åº“éªŒè¯ç­”æ¡ˆ",
                    "å¯¹åŸºæœ¬å¸¸è¯†é—®é¢˜ä½¿ç”¨é¢„å®šä¹‰ç­”æ¡ˆ"
                ]
            })
        
        if "fabrication" in issue_types or "lack_of_honesty" in issue_types:
            recommendations.append({
                "priority": "critical",
                "category": "è¯šå®æ€§",
                "actions": [
                    "å¼ºåŒ–ç³»ç»Ÿæç¤ºè¯ï¼Œè¦æ±‚æ‰¿è®¤ä¸çŸ¥é“",
                    "æ·»åŠ æ¦‚å¿µéªŒè¯æœºåˆ¶",
                    "å®ç°ç½®ä¿¡åº¦è¯„ä¼°",
                    "å¯¹è™šæ„æ¦‚å¿µè¿”å›æ ‡å‡†å›å¤"
                ]
            })
        
        if "numerical_deviation" in issue_types or "magnitude_error" in issue_types:
            recommendations.append({
                "priority": "high",
                "category": "æ•°å€¼å‡†ç¡®æ€§",
                "actions": [
                    "å»ºç«‹æ•°å€¼çŸ¥è¯†åº“",
                    "æ·»åŠ æ•°å€¼éªŒè¯æœºåˆ¶",
                    "ä½¿ç”¨æ›´ä½çš„temperatureå‚æ•°",
                    "å¯¹æ•°å€¼é—®é¢˜æ·»åŠ å•ä½å’Œç²¾åº¦è¯´æ˜"
                ]
            })
        
        if "no_source_or_limitation" in issue_types or "possible_fabricated_source" in issue_types:
            recommendations.append({
                "priority": "high",
                "category": "æ¥æºå½’å±",
                "actions": [
                    "åœ¨ç³»ç»Ÿæç¤ºè¯ä¸­æ˜ç¡®çŸ¥è¯†æˆªæ­¢æ—¥æœŸ",
                    "è¦æ±‚å¯¹æœ€æ–°ä¿¡æ¯è¯´æ˜æ— æ³•è·å–",
                    "ç¦æ­¢ç¼–é€ è®ºæ–‡å’Œç ”ç©¶å¼•ç”¨",
                    "å»ºè®®ç”¨æˆ·æŸ¥é˜…æƒå¨æ¥æº"
                ]
            })
        
        if "low_consistency" in issue_types or "contradictory_key_info" in issue_types:
            recommendations.append({
                "priority": "medium",
                "category": "ä¸€è‡´æ€§",
                "actions": [
                    "é™ä½temperatureå‚æ•°",
                    "ä½¿ç”¨å›ºå®šçš„éšæœºç§å­",
                    "å¯¹ç›¸åŒé—®é¢˜ä½¿ç”¨ç¼“å­˜",
                    "æ·»åŠ ä¸€è‡´æ€§éªŒè¯æœºåˆ¶"
                ]
            })
        
        return recommendations
    
    def run_diagnosis(self, base_url=None):
        """è¿è¡Œå®Œæ•´è¯Šæ–­"""
        print("="*70)
        print("å¹»è§‰æµ‹è¯•è¯Šæ–­å·¥å…·")
        print("="*70)
        
        url = base_url or BASE_URL
        print(f"\næµ‹è¯•URL: {url}")
        print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        # è¿è¡Œå¹»è§‰æµ‹è¯•
        print("æ­£åœ¨è¿è¡Œå¹»è§‰æ£€æµ‹æµ‹è¯•...")
        tester = HallucinationTest(url)
        
        tester.test_factual_accuracy()
        tester.test_unknown_knowledge()
        tester.test_numerical_accuracy()
        tester.test_source_attribution()
        tester.test_consistency()
        
        # è¯Šæ–­æ¯ä¸ªæµ‹è¯•ç»“æœ
        all_issues = {}
        
        for result in tester.results:
            print(f"\n{'='*70}")
            print(f"æµ‹è¯•: {result.name}")
            print(f"çŠ¶æ€: {'âœ“ é€šè¿‡' if result.passed else 'âœ— å¤±è´¥'}")
            print(f"å¾—åˆ†: {result.score:.1f}/100")
            print(f"è€—æ—¶: {result.duration:.2f}s")
            
            if not result.passed:
                # æ ¹æ®æµ‹è¯•ç±»å‹è¿›è¡Œè¯Šæ–­
                if "äº‹å®å‡†ç¡®æ€§" in result.name:
                    issues = self.diagnose_factual_accuracy(result)
                elif "æœªçŸ¥çŸ¥è¯†" in result.name:
                    issues = self.diagnose_unknown_knowledge(result)
                elif "æ•°å€¼å‡†ç¡®æ€§" in result.name:
                    issues = self.diagnose_numerical_accuracy(result)
                elif "æ¥æºå½’å±" in result.name:
                    issues = self.diagnose_source_attribution(result)
                elif "ä¸€è‡´æ€§" in result.name:
                    issues = self.diagnose_consistency(result)
                else:
                    issues = []
                
                all_issues[result.name] = issues
                
                if issues:
                    print(f"\nå‘ç° {len(issues)} ä¸ªé—®é¢˜:")
                    for i, issue in enumerate(issues, 1):
                        severity_label = self.severity_levels.get(issue['severity'], issue['severity'])
                        print(f"\n  {i}. [{severity_label}] {issue['description']}")
                        if 'response_preview' in issue:
                            print(f"     å“åº”é¢„è§ˆ: {issue['response_preview'][:100]}...")
        
        # ç”Ÿæˆå»ºè®®
        print(f"\n{'='*70}")
        print("ä¿®å¤å»ºè®®")
        print("="*70)
        
        recommendations = self.generate_recommendations(all_issues)
        
        if recommendations:
            for rec in recommendations:
                priority_emoji = {
                    "critical": "ğŸ”´",
                    "high": "ğŸŸ ",
                    "medium": "ğŸŸ¡",
                    "low": "ğŸŸ¢"
                }
                emoji = priority_emoji.get(rec['priority'], "")
                
                print(f"\n{emoji} {rec['category']} (ä¼˜å…ˆçº§: {rec['priority']})")
                for action in rec['actions']:
                    print(f"  â€¢ {action}")
        else:
            print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œæ— éœ€ä¿®å¤ï¼")
        
        # ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
        report = {
            "timestamp": datetime.now().isoformat(),
            "url": url,
            "total_tests": len(tester.results),
            "passed_tests": sum(1 for r in tester.results if r.passed),
            "failed_tests": sum(1 for r in tester.results if not r.passed),
            "average_score": sum(r.score for r in tester.results) / len(tester.results),
            "issues": all_issues,
            "recommendations": recommendations
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = f"hallucination_diagnosis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\n{'='*70}")
        print(f"è¯Šæ–­æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        print("="*70)
        
        return report


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å¹»è§‰æµ‹è¯•è¯Šæ–­å·¥å…·')
    parser.add_argument(
        '--url',
        default=BASE_URL,
        help='æ™ºèƒ½ä½“APIåœ°å€ (é»˜è®¤: http://10.225.8.186/api/v1)'
    )
    
    args = parser.parse_args()
    
    diagnostic = HallucinationDiagnostic()
    diagnostic.run_diagnosis(args.url)


if __name__ == "__main__":
    main()

